{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lec 28 - SVCs\n",
    "## CMSE 381 - Fall 2023\n",
    "## Nov 15, 2023\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# ML imports we've used previously\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aa0b0",
   "metadata": {},
   "source": [
    "In this module we are going to test out the SVC methods discussed in class. The book's definitions as we talked about in class are:\n",
    "\n",
    "- *Maximal Margin Classifiers*, where the goal was to find a separating hyperplane with no misclassifications, \n",
    "- *Support vector classifiers*, where we allow for a soft margin and hence some data points can end up either on the wrong side of the margin or the wrong side of the hyperplane. \n",
    "\n",
    "The `sklearn` function to do this is `SVC`.  This can do either version above as long as we pass the correct  to do all of this, and we can basically trick it (by understanding the innards) into doing any of them.  **<font color=red>However, there are two things that will likely be confusing. </font>**\n",
    "- The command is just called `SVC`, but you should thinking of it as doing the most general SVM as defined in the book (we'll cover this next class) and then we can modify our inputs to allow for the other options as necessary.\n",
    "- The cost input parameter is **not** the same as the `C` defined in the book. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aee9fd",
   "metadata": {},
   "source": [
    "The code below is to make plotting easier later.  Once you have your $\\beta_0$, $\\beta_1$, $\\beta_2$ you should be able to easily draw the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41faceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLine(b0,b1,b2,xmin = -2, xmax = 5):\n",
    "    \"\"\"\n",
    "    Pass in your coefficients to draw the line \n",
    "    b0 + b1 * X_1 + b2 * X_2 = 0\n",
    "    \"\"\"\n",
    "    a = -b1 / b2\n",
    "    xx = np.linspace(xmin,xmax)\n",
    "    yy = a * xx - b0 / b2\n",
    "\n",
    "    plt.plot(xx,yy)\n",
    "    \n",
    "\n",
    "plotLine(2,-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59908b84",
   "metadata": {},
   "source": [
    "For now, we're going to mess with some synthetic data (meaning I generated it and saved it as a CSV for you). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../../DataSets/SVM-Data.csv', \n",
    "                delimiter=' ', \n",
    "                header = None, \n",
    "                )\n",
    "\n",
    "data_df.columns = ['X1','X2', 'y']\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79814328",
   "metadata": {},
   "source": [
    "Here's a few helpful subsets of the data we can use for later drawing depending on what we want to do with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ced5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the X and y as numpy arrays\n",
    "X = data_df[['X1','X2']].values \n",
    "y = data_df['y'].values\n",
    "\n",
    "# Just the data points where the y value is 1\n",
    "X_pos = X[y>0]\n",
    "\n",
    "# Just the data points where the y value is -1\n",
    "X_neg = X[y<0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pos[:,0], X_pos[:,1], label = 'y = +1', marker = 'x')\n",
    "plt.scatter(X_neg[:,0], X_neg[:,1], label = 'y = -1', marker = 's')\n",
    "plt.legend()\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4324cc3",
   "metadata": {},
   "source": [
    "And then, tada! Here's all it takes to fit your support vector classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42911398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1, kernel='linear', )\n",
    "svc.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ff390",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Use your trained model to figure out the equation of the hyperplane (hint: go looking for the `coef_` and `intercept_`). Plot it on a graph with the data points (see above for the `plotLine` function!).  Does the resulting hyperplane seem reasonable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda09d9",
   "metadata": {},
   "source": [
    "Remember that the SVC setting only uses a subset of observations, called *support vectors* to actually determine this hyperplane. The `svc` object keeps track of those for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the indices of the support vectors from our original X matrix\n",
    "\n",
    "svc.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3091d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It also keeps track of the points themselves \n",
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d1eb7",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Draw a scatter plot of these points on top of the drawing you've already been building with some different marker.  Do these points make sense to be the support vectors?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c612f0",
   "metadata": {},
   "source": [
    "Now that you have a sense of what's going on in the svc function, I've built you a function that will make this nice drawing for us without much effort.  We can hand it our `X` and `y` data, along with the trained `svc` to get the plot, with some added stuff, including dashed lines for the margin and colors for which side of the hyperplane you're on (blue for -1, red for +1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58955e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to define the function\n",
    "def plot_svc(svc, X, y, h=0.02, pad=0.25):\n",
    "    x_min, x_max = X[:, 0].min()-pad, X[:, 0].max()+pad\n",
    "    y_min, y_max = X[:, 1].min()-pad, X[:, 1].max()+pad\n",
    "    xvec = np.arange(x_min, x_max, h)\n",
    "    yvec = np.arange(y_min, y_max, h)\n",
    "    xx, yy = np.meshgrid(xvec,yvec )\n",
    "    \n",
    "    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.2)\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], s=70, c=y, cmap=mpl.cm.Paired)\n",
    "    # Support vectors indicated in plot by X's\n",
    "    sv = svc.support_vectors_\n",
    "    plt.scatter(sv[:,0], sv[:,1], c='k', marker='x', s=100, linewidths=1)\n",
    "    \n",
    "    if svc.kernel == 'linear':\n",
    "        # Get the margin lines \n",
    "        w = svc.coef_[0]\n",
    "        a = -w[0] / w[1]\n",
    "        yhyperplane = a * xvec - (svc.intercept_[0]) / w[1]\n",
    "        margin = 1 / np.sqrt(np.sum(svc.coef_ ** 2))\n",
    "        ymargin_down = yhyperplane+  - np.sqrt(1 + a ** 2) * margin\n",
    "        ymargin_up = yhyperplane + np.sqrt(1 + a ** 2) * margin\n",
    "        plt.plot(xvec,ymargin_down, \"k--\")\n",
    "        plt.plot(xvec,ymargin_up, \"k--\")\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()\n",
    "    print('Number of support vectors: ', svc.support_.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5acac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#From here on, you can just use this command to plot.\n",
    "plot_svc(svc, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65046b42",
   "metadata": {},
   "source": [
    "## Messing with $C$\n",
    "\n",
    "Below we have the model fit using several choices for $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43527276",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=10e-2, kernel='linear', )\n",
    "svc.fit(X, y)\n",
    "plot_svc(svc, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d85b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1, kernel='linear', )\n",
    "svc.fit(X, y)\n",
    "plot_svc(svc, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a65602",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=10e5, kernel='linear', )\n",
    "svc.fit(X, y)\n",
    "plot_svc(svc, X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73621bf6",
   "metadata": {},
   "source": [
    "**WARNING**: \n",
    "The $C$ in the class/textbook and the $C$ used as input to the `SVC` command are **NOT THE SAME**.\n",
    "- The cost $C$ in class had the property that big $C$ meant big margin \n",
    "- This is a DIFFERENT $C$. In this case, big $C$ means small margin. \n",
    "\n",
    "They're both serving the same purpose, i.e. to control how tolerant we are to misclassifications. \n",
    "\n",
    "The following code uses some nice functions in `sklearn` to do a CV test to determine the best $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4584942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the optimal C parameter by cross-validation\n",
    "C_list = [0.001, 0.01, 0.1, 1, 5, 10, 100]\n",
    "tuned_parameters = [{'C': C_list}]\n",
    "clf = GridSearchCV(SVC(kernel='linear'), tuned_parameters, cv=10, scoring='accuracy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7935ad",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Use the `clf.cv_results_` function to determine which $C$ give the best score (note there could be ties). Which $C$ did the function choose? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faaae83",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Load in the `SVM-Data2.csv` data from the folder. Run this same analysis again, namily: \n",
    "- Use the `GridSearchCV` function to determine the best choice of $C$.\n",
    "- Train an individual `SVC` instance with $C$ set to that value.  Then you can draw the resulting model with the `plot_svc` function from earlier. How does the model do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
